{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinopiaggi/summarize/blob/main/Martino_Summarize_videos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkogwIy7IfQO"
      },
      "source": [
        "# Summarization notebook with AIs\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Repository: https://github.com/martinopiaggi/summarize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "jwROe6WH2lZi"
      },
      "outputs": [],
      "source": [
        "Source = \"https://www.youtube.com/watch?v=3Oij7CJwfpM&list=WL&index=4\" #@param {type:\"string\"}\n",
        "Type_of_source = \"Youtube video or playlist\" #@param ['Text', 'Youtube video or playlist', 'Videos on Google Drive folder','Dropbox video link']\n",
        "\n",
        "Type = Type_of_source\n",
        "\n",
        "if Type == 'Youtube video or playlist':\n",
        "  URL = Source\n",
        "\n",
        "if Type == 'Dropbox video link':\n",
        "  dropbox_URL = Source\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown If source is video, you want timestamps in final summary?\n",
        "Timestamps = True #@param {type:\"boolean\"}\n",
        "#@markdown Desired output length as percentual of original length\n",
        "Min_percentual_summary = 0.2 #@param {type:\"number\"}\n",
        "Max_percentual_summary = 0.6 #@param {type:\"number\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sJnZWCPc3uOH",
        "outputId": "ac2406bb-d252-4bca-d64b-f3c698c94471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.0)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
            "Collecting faster-whisper\n",
            "  Downloading faster_whisper-0.9.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting av==10.* (from faster-whisper)\n",
            "  Downloading av-10.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ctranslate2<4,>=3.17 (from faster-whisper)\n",
            "  Downloading ctranslate2-3.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.17.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.14.1)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster-whisper)\n",
            "  Downloading onnxruntime-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->faster-whisper) (1.23.5)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->faster-whisper) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (23.2)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (23.5.26)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Installing collected packages: av, humanfriendly, ctranslate2, coloredlogs, onnxruntime, faster-whisper\n",
            "Successfully installed av-10.0.0 coloredlogs-15.0.1 ctranslate2-3.20.0 faster-whisper-0.9.0 humanfriendly-10.0 onnxruntime-1.16.1\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2023.10.13-py2.py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mutagen (from yt-dlp)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt-dlp)\n",
            "  Downloading pycryptodomex-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets (from yt-dlp)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2023.7.22)\n",
            "Collecting brotli (from yt-dlp)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: brotli, websockets, pycryptodomex, mutagen, yt-dlp\n",
            "Successfully installed brotli-1.1.0 mutagen-1.47.0 pycryptodomex-3.19.0 websockets-12.0 yt-dlp-2023.10.13\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install tensorflow\n",
        "from transformers import pipeline,BartTokenizer, BartForConditionalGeneration\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import re\n",
        "import math\n",
        "\n",
        "if Type == (\"Youtube video or playlist\"\n",
        "            or 'Videos on Google Drive folder'\n",
        "            or \"Dropbox video link\"):\n",
        "\n",
        "  !pip install faster-whisper\n",
        "  from faster_whisper import WhisperModel\n",
        "  from pathlib import Path\n",
        "  import subprocess\n",
        "  import torch\n",
        "  import shutil\n",
        "  import numpy as np\n",
        "\n",
        "  if Type == \"Youtube video or playlist\":\n",
        "    !pip install yt-dlp\n",
        "    from pathlib import Path\n",
        "    import yt_dlp\n",
        "\n",
        "  if Type == (\"Dropbox video link\"):\n",
        "    !sudo apt update && sudo apt install ffmpeg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLIU6bAX9a9v",
        "outputId": "ce09f2ee-545e-42e2-d466-8a33b53bf08d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube:tab] Extracting URL: https://www.youtube.com/watch?v=3Oij7CJwfpM&list=WL&index=4\n",
            "[youtube:tab] Downloading playlist WL - add --no-playlist to download just the video 3Oij7CJwfpM\n",
            "[youtube:tab] WL: Downloading webpage\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube:tab] Unable to recognize playlist. Downloading just video 3Oij7CJwfpM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=3Oij7CJwfpM\n",
            "[youtube] 3Oij7CJwfpM: Downloading webpage\n",
            "[youtube] 3Oij7CJwfpM: Downloading ios player API JSON\n",
            "[youtube] 3Oij7CJwfpM: Downloading android player API JSON\n",
            "[youtube] 3Oij7CJwfpM: Downloading m3u8 information\n",
            "[info] 3Oij7CJwfpM: Downloading 1 format(s): 140\n",
            "[download] Destination: 3Oij7CJwfpM.m4a\n",
            "[download] 100% of   15.36MiB in 00:00:00 at 15.54MiB/s  \n",
            "[FixupM4a] Correcting container of \"3Oij7CJwfpM.m4a\"\n",
            "[ExtractAudio] Destination: 3Oij7CJwfpM.wav\n",
            "Deleting original file 3Oij7CJwfpM.m4a (pass -k to keep)\n",
            "[youtube:tab] Extracting URL: https://www.youtube.com/watch?v=3Oij7CJwfpM&list=WL&index=4\n",
            "[youtube:tab] Downloading playlist WL - add --no-playlist to download just the video 3Oij7CJwfpM\n",
            "[youtube:tab] WL: Downloading webpage\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube:tab] Unable to recognize playlist. Downloading just video 3Oij7CJwfpM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=3Oij7CJwfpM\n",
            "[youtube] 3Oij7CJwfpM: Downloading webpage\n",
            "[youtube] 3Oij7CJwfpM: Downloading ios player API JSON\n",
            "[youtube] 3Oij7CJwfpM: Downloading android player API JSON\n",
            "[youtube] 3Oij7CJwfpM: Downloading m3u8 information\n"
          ]
        }
      ],
      "source": [
        "if Type == \"Youtube video or playlist\":\n",
        "  video_path_local_list = []\n",
        "\n",
        "  ydl_opts = {\n",
        "  'format': 'm4a/bestaudio/best',\n",
        "  'outtmpl': '%(id)s.%(ext)s',\n",
        "  # ℹ️ See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments\n",
        "  'postprocessors': [{  # Extract audio using ffmpeg\n",
        "  'key': 'FFmpegExtractAudio',\n",
        "  'preferredcodec': 'wav',\n",
        "  }]\n",
        "  }\n",
        "\n",
        "  with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    error_code = ydl.download([URL])\n",
        "    list_video_info = [ydl.extract_info(URL, download=False)]\n",
        "\n",
        "  for video_info in list_video_info:\n",
        "    video_path_local_list.append(Path(f\"{video_info['id']}.wav\"))\n",
        "\n",
        "  #for video_path_local in video_path_local_list:\n",
        "   # if video_path_local.suffix == \".mp4\":\n",
        "    #    video_path_local = video_path_local.with_suffix(\".wav\")\n",
        "    #result  = subprocess.run([\"ffmpeg\", \"-i\", str(video_path_local.with_suffix(\".mp4\")), \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", str(video_path_local)])\n",
        "\n",
        "\n",
        "if Type == (\"Dropbox video link\"):\n",
        "    !wget -O dropbox_video.mp4 $dropbox_URL\n",
        "    !ffmpeg -i dropbox_video.mp4 -vn -acodec pcm_s16le -ar 16000 -ac 1 dropbox_video_audio.wav\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "iOTFm1vPAVDh"
      },
      "outputs": [],
      "source": [
        "language = \"en\"\n",
        "initial_prompt = \"\"\n",
        "Text = \"\"\n",
        "\n",
        "video_path_local = str(video_path_local_list[0])\n",
        "\n",
        "if Type == (\"Dropbox video link\"):\n",
        "    video_path_local = \"dropbox_video_audio.wav\"\n",
        "\n",
        "\n",
        "if Type is not (\"Text\" or \"Text from Google Drive\"):\n",
        "\n",
        "  model = WhisperModel('small', device=\"cuda\", compute_type='int8')\n",
        "  segments, info = model.transcribe(str(video_path_local), beam_size=5,\n",
        "                                    language=None if language == \"auto\" else language,\n",
        "                                    task=\"translate\",\n",
        "                                    initial_prompt=initial_prompt)\n",
        "\n",
        "  transcript_file_name = video_path_local.replace(\".wav\", \".txt\")\n",
        "  with open(transcript_file_name, 'w') as f:\n",
        "    for segment in segments:\n",
        "      Text += segment.text.strip()\n",
        "    f.write(Text+\". \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "7NnXQzbOE_e5"
      },
      "outputs": [],
      "source": [
        "#Clean cache to avoid Colab crash in case of multiple runs\n",
        "torch.cuda.empty_cache()\n",
        "#Whisper model no longer necessary\n",
        "del model\n",
        "#load model\n",
        "model_name = \"facebook/bart-large-cnn\"\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name).to(\"cuda:0\")\n",
        "\n",
        "if Type is not (\"Text\" or \"Text from Google Drive\"):\n",
        "  Text = open(transcript_file_name, \"r\").read()\n",
        "  if Type == \"Dropbox video link\":\n",
        "    Text = open(\"dropbox_video_audio.txt\", \"r\").read()\n",
        "\n",
        "\n",
        "# Define the TextDataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.texts = texts\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.texts[idx]\n",
        "\n",
        "\n",
        "# Tokenize the text and split into batches\n",
        "texts = [Text[i:i+512] for i in range(0, len(Text), 512)]\n",
        "dataset = TextDataset(texts)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "summary = ''\n",
        "\n",
        "for batch in dataloader:\n",
        "\n",
        "    # Convert the batch to the appropriate format\n",
        "    encoded_inputs = tokenizer(batch, truncation=True, padding=True, return_tensors=\"pt\", max_length=512).to(\"cuda:0\")\n",
        "\n",
        "    # Determine max_length and min_length based on input length\n",
        "    min_length = int(Min_percentual_summary * encoded_inputs[\"input_ids\"].size(1))\n",
        "    max_length = int(Max_percentual_summary * encoded_inputs[\"input_ids\"].size(1))\n",
        "\n",
        "    summaries_output = model.generate(\n",
        "        input_ids=encoded_inputs[\"input_ids\"],\n",
        "        attention_mask=encoded_inputs[\"attention_mask\"],\n",
        "        num_beams=4,\n",
        "        length_penalty=0.6,\n",
        "        no_repeat_ngram_size=2,\n",
        "        min_length=min_length,  # Set the min_length\n",
        "        max_length=max_length   # Set the max_length\n",
        "    )\n",
        "\n",
        "\n",
        "    # Decode each summarized output and append to the final summary\n",
        "    for idx, output in enumerate(summaries_output):\n",
        "        decoded_summary = tokenizer.decode(output, skip_special_tokens=True)\n",
        "        summary += decoded_summary\n",
        "\n",
        "# Save the summary\n",
        "\n",
        "final_name = 'summary_'\n",
        "if Type is not (\"Text\" or \"Text from Google Drive\"):\n",
        "  final_name += transcript_file_name\n",
        "  if Type == \"Dropbox video link\":\n",
        "    final_name += \"dropbox_video_audio.txt\"\n",
        "\n",
        "with open(final_name, 'w') as f:\n",
        "    f.write(summary)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVxOYrSl2Nxiy9dXPNEKH8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}