{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinopiaggi/summarize/blob/main/Martino_Summarize_videos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarization notebook with AIs\n",
        "\n",
        "Repository: https://github.com/martinopiaggi/summarize"
      ],
      "metadata": {
        "id": "xkogwIy7IfQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Source of the summary\n",
        "#@markdown ## **Type**\n",
        "Type = \"Dropbox video link\" #@param ['Text', 'Text from Google Drive','Youtube video or playlist', 'Videos on Google Drive folder','Dropbox video link']\n",
        "#@markdown (*Run this cell again if you change the source*)\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### **Text**\n",
        "#@markdown (*only if type is text*)\n",
        "Text = \"\" #@param {type:\"string\"}\n",
        "#@markdown #### **Youtube video or playlist**\n",
        "#@markdown (*only if type is yt videos*)\n",
        "URL = \"https://www.youtube.com/watch?v=VqnF1TTkKV0\" #@param {type:\"string\"}\n",
        "#@markdown #### **Google Drive video**\n",
        "#@markdown *audio (mp4, wav), or folder containing video and/or audio files*\n",
        "#@markdown (*only if type is from Google Drive*)\n",
        "video_path = \"Colab Notebooks/transcription/my_video.mp4\" #@param {type:\"string\"}\n",
        "#@markdown #### **Dropbox link video**\n",
        "#@markdown *The video share link which allows anyone to view it*\n",
        "dropbox_URL = \"\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown #### If source is video, you want timestamps in final summary?\n",
        "Timestamps = True #@param {type:\"boolean\"}\n",
        "\n",
        "if Type is (\"Text\" or \"Text from Google Drive\"):\n",
        "  Timestamps = False"
      ],
      "metadata": {
        "id": "jwROe6WH2lZi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O dropbox_video.mp4\n"
      ],
      "metadata": {
        "id": "8daPVlQw6Iu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!ffmpeg -i dropbox_video.mp4 -vn -acodec copy dropbox_video_audio.wav"
      ],
      "metadata": {
        "id": "PC9CLRTf9CtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown # Install libraries\n",
        "#@markdown This cell will take a little while to download several libraries\n",
        "\n",
        "#@markdown ---\n",
        "!pip install transformers\n",
        "!pip install tensorflow\n",
        "from transformers import pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\",device=0)\n",
        "\n",
        "import re\n",
        "import math\n",
        "\n",
        "if Type == (\"Youtube video or playlist\" or 'Videos on Google Drive folder'):\n",
        "\n",
        "  video_path_local_list = []\n",
        "  ! pip install faster-whisper\n",
        "  from faster_whisper import WhisperModel\n",
        "  from pathlib import Path\n",
        "  import subprocess\n",
        "  import torch\n",
        "  import shutil\n",
        "  import numpy as np\n",
        "\n",
        "  model = WhisperModel('small', device=\"cuda\", compute_type='int8')\n",
        "\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "  !pip install yt-dlp\n",
        "  from pathlib import Path\n",
        "  import yt_dlp\n",
        "\n",
        "  ydl_opts = {\n",
        "  'format': 'm4a/bestaudio/best',\n",
        "  'outtmpl': '%(id)s.%(ext)s',\n",
        "  # ℹ️ See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments\n",
        "  'postprocessors': [{  # Extract audio using ffmpeg\n",
        "  'key': 'FFmpegExtractAudio',\n",
        "  'preferredcodec': 'wav',\n",
        "  }]\n",
        "  }\n",
        "\n",
        "  with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    error_code = ydl.download([URL])\n",
        "    list_video_info = [ydl.extract_info(URL, download=False)]\n",
        "\n",
        "  for video_info in list_video_info:\n",
        "    video_path_local_list.append(Path(f\"{video_info['id']}.wav\"))\n",
        "\n",
        "  for video_path_local in video_path_local_list:\n",
        "    if video_path_local.suffix == \".mp4\":\n",
        "        video_path_local = video_path_local.with_suffix(\".wav\")\n",
        "    result  = subprocess.run([\"ffmpeg\", \"-i\", str(video_path_local.with_suffix(\".mp4\")), \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", str(video_path_local)])\n"
      ],
      "metadata": {
        "id": "sJnZWCPc3uOH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eLIU6bAX9a9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOTFm1vPAVDh"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "\n",
        "\n",
        "if Type is not (\"Text\" or \"Text from Google Drive\"):\n",
        "\n",
        "  def seconds_to_time_format(s):\n",
        "      # Convert seconds to hours, minutes, seconds, and milliseconds\n",
        "      hours = s // 3600\n",
        "      s %= 3600\n",
        "      minutes = s // 60\n",
        "      s %= 60\n",
        "      seconds = s // 1\n",
        "      milliseconds = round((s % 1) * 1000)\n",
        "\n",
        "      # Return the formatted string\n",
        "      return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}\"\n",
        "\n",
        "\n",
        "  #@markdown # Trascription\n",
        "  #@markdown Trascription of videos (if needed)\n",
        "  language = \"auto\" #@param [\"auto\", \"en\", \"zh\", \"ja\", \"fr\", \"de\"] {allow-input: true}\n",
        "  initial_prompt = \"Here are some English words you may need: OneDrive\" #@param {type:\"string\"}\n",
        "\n",
        "  segments, info = model.transcribe(str(video_path_local), beam_size=5,\n",
        "                                    language=None if language == \"auto\" else language,\n",
        "                                    initial_prompt=initial_prompt,\n",
        "                                    vad_filter=True, #voice activity detection\n",
        "                                    vad_parameters=dict(min_silence_duration_ms=50))\n",
        "\n",
        "  ext_name = \".srt\"\n",
        "  transcript_file_name = video_path_local.stem + ext_name\n",
        "  sentence_idx = 1\n",
        "  with open(transcript_file_name, 'w') as f:\n",
        "    for segment in segments:\n",
        "      if Timestamps:\n",
        "        ts_start = seconds_to_time_format(segment.start)\n",
        "        ts_end = seconds_to_time_format(segment.end)\n",
        "        f.write(f\"{ts_start} -> {ts_end} \")\n",
        "      f.write(f\"{segment.text.strip()}\\n\")\n",
        "      sentence_idx = sentence_idx + 1\n",
        "\n",
        "  try:\n",
        "    shutil.copy(video_path_local.parent / transcript_file_name,\n",
        "              drive_whisper_path / transcript_file_name\n",
        "    )\n",
        "    display(Markdown(f\"**Transcript file created: {drive_whisper_path / transcript_file_name}**\"))\n",
        "  except:\n",
        "    display(Markdown(f\"**Transcript file created: {video_path_local.parent / transcript_file_name}**\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NnXQzbOE_e5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "#@markdown # Summarization\n",
        "#@markdown Using https://huggingface.co/facebook/bart-large-cnn\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\",device=0)\n",
        "tokenizer = summarizer.tokenizer\n",
        "\n",
        "if Type is not (\"Text\" or \"Text from Google Drive\"):\n",
        "  Text = open(transcript_file_name, \"r\").read()\n",
        "\n",
        "Text = re.sub(r'\\n', ' ', Text)\n",
        "\n",
        "tokens = tokenizer.encode(Text.strip())\n",
        "\n",
        "# Calculate the number of chunks needed\n",
        "chunk_len = math.ceil(len(tokens) / 512)\n",
        "chunksNumber = len(tokens)//chunk_len\n",
        "\n",
        "# Split the tokens into chunks\n",
        "chunks = [tokens[i:i+chunksNumber] for i in range(0, len(tokens), chunksNumber)]\n",
        "\n",
        "if(len(chunks)>1):\n",
        "  if (len(chunks[-1]) + len(chunks[-2])) < 1024:\n",
        "      merged_chunk = chunks.pop(-1) + chunks.pop(-1)\n",
        "      chunks.append(merged_chunk)\n",
        "\n",
        "summary = ''\n",
        "\n",
        "for chunk in chunks:\n",
        "    if Timestamps:\n",
        "      chunkText = tokenizer.decode(chunk);\n",
        "      init_ts = re.findall(r\"\\d{2}:\\d{2}:\\d{2} -\", chunkText)[0]\n",
        "      end_ts = re.findall(r\"> \\d{2}:\\d{2}:\\d{2} \", chunkText)[-1]\n",
        "      chunkText = re.sub(r\"(\\d{2}:?)* -> (\\d{2}:?)*\", '', chunkText)\n",
        "\n",
        "    # Set max_length and min_length based on token count\n",
        "    max_length = len(chunk) // 3\n",
        "    min_length = len(chunk) // 5\n",
        "\n",
        "    #Generate summary for each chunk without sampling (example)\n",
        "    summary_chunk = summarizer(chunkText, max_length=max_length, min_length=min_length, do_sample=True)\n",
        "    if Timestamps:\n",
        "      summary += init_ts\n",
        "      summary += end_ts + ' '\n",
        "    summary += summary_chunk[0]['summary_text'] + \"\\n\"\n",
        "\n",
        "print(summary)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+b0VRDRcA8/M5X1HJ6zM3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}