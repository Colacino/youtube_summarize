{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkogwIy7IfQO"
      },
      "source": [
        "# Transcription and summarization notebook with AIs\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Repository: https://github.com/martinopiaggi/summarize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "jwROe6WH2lZi",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "Source = \"\" #@param {type:\"string\"}\n",
        "Type_of_source = \"Youtube video or playlist\" #@param ['Youtube video or playlist', 'Google Drive video link','Dropbox video link']\n",
        "Type = Type_of_source\n",
        "URL = Source\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Insert your API key depending on which endpoint you want to use (by default Groq)\n",
        "api_key = \"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\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "#@markdown Do you want to use OpenAI endpoint ?\n",
        "OpenAI_endpoint = False  #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Do you want to use Youtube captions ?\n",
        "use_Youtube_captions = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Other settings\n",
        "\n",
        "#@markdown You want timestamps in final text?\n",
        "Timestamps = True #@param {type:\"boolean\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "sJnZWCPc3uOH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#@markdown ## Installation of libraries\n",
        "#@markdown Installation of libraries\n",
        "\n",
        "import subprocess\n",
        "import re\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "if use_Youtube_captions:\n",
        "  !pip install youtube-transcript-api\n",
        "  from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "if (not Type == \"Youtube video or playlist\") or (not use_Youtube_captions):\n",
        "  import torch\n",
        "  from torch.utils.data import Dataset, DataLoader\n",
        "  !pip install faster-whisper\n",
        "  from faster_whisper import WhisperModel\n",
        "\n",
        "\n",
        "if OpenAI_endpoint:\n",
        "  !pip install openai\n",
        "  import openai\n",
        "  client = openai.OpenAI(api_key=api_key)\n",
        "else:\n",
        "  !pip install groq\n",
        "  from groq import Groq\n",
        "  client = Groq(api_key=api_key)\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "  !pip install git+https://github.com/pytube/pytube\n",
        "  from pytube import YouTube\n",
        "\n",
        "if Type == \"Google Drive video link\":\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "\n",
        "if Type == (\"Dropbox video link\"):\n",
        "  !sudo apt update && sudo apt install ffmpeg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "eLIU6bAX9a9v",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Video downloads\n",
        "#@markdown Downloading video sources\n",
        "video_path_local_list = []\n",
        "skip_transcription=False\n",
        "\n",
        "Text = \"\"\n",
        "TextTimestamps = \"\"\n",
        "\n",
        "def seconds_to_time_format(s):\n",
        "    hours = s // 3600\n",
        "    s %= 3600\n",
        "    minutes = s // 60\n",
        "    s %= 60\n",
        "    seconds = s // 1\n",
        "    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}\"\n",
        "\n",
        "\n",
        "\n",
        "def download_youtube_audio_only(url, output_dir=\".\", filename=None, filename_prefix=None, skip_existing=True, timeout=None, max_retries=0):\n",
        "    yt = YouTube(url)\n",
        "    audio_stream = yt.streams.get_audio_only()\n",
        "    # Prepare the filename if a prefix is provided.\n",
        "    if filename_prefix and filename:\n",
        "        filename = f\"{filename_prefix}{filename}\"\n",
        "    elif filename_prefix:\n",
        "        filename = f\"{filename_prefix}{audio_stream.default_filename}\"\n",
        "    # Download the audio stream.\n",
        "    saved_path = audio_stream.download(output_path=output_dir, filename=filename, skip_existing=skip_existing, timeout=timeout, max_retries=max_retries)\n",
        "    return saved_path\n",
        "\n",
        "\n",
        "def download_youtube_captions(url):\n",
        "    regex = r'(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})'\n",
        "    video_id =  re.search(regex, url).group(1)\n",
        "    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "\n",
        "    try:\n",
        "      transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\n",
        "    except:\n",
        "      for available_transcript in transcript_list:\n",
        "        if available_transcript.is_translatable:\n",
        "          transcript = available_transcript.translate('en').fetch()\n",
        "          break\n",
        "\n",
        "    text = \"\"\n",
        "    textTimestamps = \"\"\n",
        "    for entry in transcript:\n",
        "            start_time = seconds_to_time_format(entry['start'])\n",
        "            text += entry['text'].strip() + \" \"\n",
        "            textTimestamps += f\"[{start_time}] {entry['text'].strip()}\\n\"\n",
        "\n",
        "    transcript_file_name = f\"{video_id}_captions.txt\"\n",
        "    transcript_file_name_timestamps = f\"{video_id}_captions_with_timestamps.txt\"\n",
        "\n",
        "    with open(transcript_file_name, 'w', encoding='utf-8') as f:\n",
        "      f.write(Text)\n",
        "\n",
        "    with open(transcript_file_name_timestamps, 'w', encoding='utf-8') as ft:\n",
        "      ft.write(TextTimestamps)\n",
        "\n",
        "    return text, textTimestamps , transcript_file_name , transcript_file_name_timestamps\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "    if use_Youtube_captions:\n",
        "      Text, TextTimestamps, transcript_file_name , transcript_file_name_timestamps = download_youtube_captions(URL)\n",
        "      skip_transcription=True\n",
        "    else:\n",
        "      download_youtube_audio_only(URL)\n",
        "      video_path_local_list.append(audio_path)\n",
        "\n",
        "elif Type == \"Google Drive video link\":\n",
        "  subprocess.run(['ffmpeg', '-y', '-i', '/gdrive/My Drive/' + URL, '-vn', '-acodec', 'pcm_s16le',\n",
        "                  '-ar', '16000', '-ac', '1', 'gdrive_audio.wav'], check=True)\n",
        "  video_path_local_list.append(\"gdrive_audio.wav\")\n",
        "\n",
        "elif Type == \"Dropbox video link\":\n",
        "    subprocess.run(['wget', '-O', 'dropbox_video.mp4', UnprocessableEntityError], check=True)\n",
        "    subprocess.run(['ffmpeg', '-y', '-i', 'dropbox_video.mp4', '-vn', '-acodec', 'pcm_s16le',\n",
        "                    '-ar', '16000', '-ac', '1', 'dropbox_video_audio.wav'], check=True)\n",
        "    video_path_local_list.append(\"dropbox_video_audio.wav\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOTFm1vPAVDh",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# @markdown ## Transcription using Faster Whisper\n",
        "# @markdown Manually specifying the language can increase speed.\n",
        "\n",
        "if not skip_transcription:\n",
        "\n",
        "  language = \"en\" # @param {type:\"string\"}\n",
        "  # @markdown An initial prompt with specific context-aware words and names can improve accuracy.\n",
        "\n",
        "  initial_prompt = \"\" # @param {type:\"string\"}\n",
        "\n",
        "  video_path_local = str(video_path_local_list[0])\n",
        "\n",
        "\n",
        "  model = WhisperModel('small', device=\"cuda\", compute_type='int8')\n",
        "  segments, info = model.transcribe(str(video_path_local), beam_size=5,\n",
        "                                    language=None if language == \"auto\" else language,\n",
        "                                    task=\"translate\",\n",
        "                                    initial_prompt=initial_prompt)\n",
        "\n",
        "  transcript_file_name = video_path_local.replace(\".mp4\", \".txt\")\n",
        "  transcript_file_name_timestamps = video_path_local.replace(\".wav\", \"\") + \"Timestamps\" + \".txt\"\n",
        "\n",
        "  with open(transcript_file_name, 'w') as f:\n",
        "    for segment in segments:\n",
        "      start_time = seconds_to_time_format(segment.start)\n",
        "      Text += segment.text.strip() + \" \"\n",
        "      TextTimestamps += f\"[{start_time}] {segment.text.strip()} \"\n",
        "\n",
        "    f.write(Text)\n",
        "    with open(transcript_file_name_timestamps, 'w') as ft:\n",
        "      ft.write(TextTimestamps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWeEGfgFAoni",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @markdown ## Summarization and elaboration\n",
        "\n",
        "prompt_type =  \"Only grammar correction with highlights\" #@param ['Summarization', 'Only grammar correction\", 'Only grammar correction with highlights']\n",
        "\n",
        "# Define your prompts (Keep them together for easier editing)\n",
        "summary_prompt_1 = \"\"\"Summarize the video transcript excerpt including a concise title that reflects the content. Wrap the title with **markdown bold notation**. Write the summary as if you are continuing a conversation without needing to signal a beginning. Here is the transcript: \"\"\"\n",
        "summary_prompt_2 = \"\"\"Repeat the following text correcting any grammatical errors  or mis-transcripted word. Focus solely on the essence of the content as if you are continuing a conversation without using any form of introduction like 'Here's the corrected text:' . Here is the text to fix: \"\"\"\n",
        "summary_prompt_3 = \"\"\"Repeat the following text correcting any grammatical errors or mis-transcripted word and **highlight the important quote with markdown bold notation**. Focus solely on the essence of the content as if you are continuing a conversation without using any form of introduction like 'Here's the corrected text:' . Here is the text to fix: \"\"\"\n",
        "\n",
        "# Display the selected prompt\n",
        "if prompt_type == 'Summarization':\n",
        "  summary_prompt = summary_prompt_1\n",
        "elif prompt_type == 'Only grammar correction':\n",
        "  summary_prompt = summary_prompt_2\n",
        "else:\n",
        "  summary_prompt = summary_prompt_3\n",
        "\n",
        "\n",
        "def query_openai_gpt(prompt, model=\"gpt-3.5-turbo\", max_tokens=4096):\n",
        "    try:\n",
        "        completion = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\":  prompt}\n",
        "            ],\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "        return completion.choices[0].message.content\n",
        "    except Exception as e:  # General exception handling\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "\n",
        "def query_groq_api(prompt, model=\"mixtral-8x7b-32768\", max_tokens=4096):\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": summary_prompt},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        model=model,\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content\n",
        "\n",
        "\n",
        "def summarize(prompt):\n",
        "    if OpenAI_endpoint:\n",
        "      return query_openai_gpt(summary_prompt + prompt)\n",
        "    else:\n",
        "      return query_groq_api(prompt)\n",
        "\n",
        "\n",
        "# Define the TextDataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.texts = texts\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.texts[idx]\n",
        "\n",
        "# Function to extract timestamp ranges\n",
        "def extract_timestamp_ranges(text_timestamp_chunks):\n",
        "    timestamp_pattern = re.compile(r'\\[(\\d{2}:\\d{2}:\\d{2})\\]')\n",
        "    ranges = []\n",
        "\n",
        "    for chunk in text_timestamp_chunks:\n",
        "        matches = timestamp_pattern.findall(chunk)\n",
        "        if matches:\n",
        "            start_time = matches[0]\n",
        "            ranges.append(f\"[{start_time}]\")\n",
        "    return ranges\n",
        "\n",
        "# Process and summarize text\n",
        "def process_and_summarize(Text, TextTimestamps=None):\n",
        "    chunk_size = 4096\n",
        "    overlap_size = 40\n",
        "\n",
        "    texts = [Text[i:i+chunk_size] for i in range(0, len(Text), chunk_size - overlap_size)]\n",
        "    dataset = TextDataset(texts)\n",
        "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    summary = ''\n",
        "    summaryTimestamps = ''\n",
        "\n",
        "    if TextTimestamps:\n",
        "        ratio = len(TextTimestamps) / len(Text)\n",
        "        timestamps_chunk_size = int(chunk_size * ratio)\n",
        "        timestamps_overlap_size = int(overlap_size * ratio)\n",
        "        text_timestamps_chunks = [TextTimestamps[i:i+timestamps_chunk_size] for i in range(0, len(TextTimestamps), timestamps_chunk_size - timestamps_overlap_size)]\n",
        "        timestamp_ranges = extract_timestamp_ranges(text_timestamps_chunks)\n",
        "\n",
        "    ts_idx = 0\n",
        "\n",
        "    for idx, batch in enumerate(dataloader):\n",
        "        text_chunk = batch[0]\n",
        "        summarized_chunk = summarize(text_chunk)\n",
        "        summary += summarized_chunk + \"\\n\"\n",
        "\n",
        "        if TextTimestamps and idx < len(timestamp_ranges):\n",
        "            newPiece = timestamp_ranges[idx] + \" \" + summarized_chunk + \"\\n\\n\"\n",
        "\n",
        "        else:\n",
        "            newPiece = summarized_chunk + \"\\n\"\n",
        "        print(newPiece)\n",
        "        summaryTimestamps += newPiece\n",
        "    # Save the final summar\n",
        "    final_name =  transcript_file_name.replace(\".txt\", \"_SUMMARY.txt\") if Type != \"Dropbox video link\" else \"summary_dropbox_video_audio.txt\"\n",
        "    with open(final_name, 'w') as f:\n",
        "        f.write(summaryTimestamps)\n",
        "\n",
        "process_and_summarize(Text, TextTimestamps)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}