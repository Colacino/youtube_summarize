{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkogwIy7IfQO"
      },
      "source": [
        "# Transcription and summarization notebook with AIs\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Repository: https://github.com/martinopiaggi/summarize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jwROe6WH2lZi",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "Source = \"https://www.youtube.com/watch?v=qFZQPvdL5fQ\" #@param {type:\"string\"}\n",
        "Type_of_source = \"Youtube video or playlist\" #@param ['Youtube video or playlist', 'Google Drive video link','Dropbox video link']\n",
        "Type = Type_of_source\n",
        "URL = Source\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Insert your API key depending on which endpoint you want to use (by default Groq, otherwise check OpenAI to use chatGpt)\n",
        "api_key = \"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\" #@param {type:\"string\"}\n",
        "\n",
        "OpenAI_endpoint = True  #@param {type:\"boolean\"}\n",
        "use_Youtube_captions = True #@param {type:\"boolean\"}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "sJnZWCPc3uOH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#@markdown ## Installation of libraries\n",
        "#@markdown Installation of libraries\n",
        "\n",
        "import subprocess\n",
        "import re\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "if use_Youtube_captions:\n",
        "  !pip install youtube-transcript-api\n",
        "  from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "if (not Type == \"Youtube video or playlist\") or (not use_Youtube_captions):\n",
        "  !pip install faster-whisper\n",
        "  from faster_whisper import WhisperModel\n",
        "\n",
        "if OpenAI_endpoint:\n",
        "  !pip install openai\n",
        "  import openai\n",
        "  client = openai.OpenAI(api_key=api_key)\n",
        "else:\n",
        "  !pip install groq\n",
        "  from groq import Groq\n",
        "  client = Groq(api_key=api_key)\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "  !pip install git+https://github.com/pytube/pytube\n",
        "  from pytube import YouTube\n",
        "\n",
        "if Type == \"Google Drive video link\":\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "\n",
        "if Type == (\"Dropbox video link\"):\n",
        "  !sudo apt update && sudo apt install ffmpeg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eLIU6bAX9a9v",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Video downloads\n",
        "#@markdown Downloading video sources\n",
        "video_path_local_list = []\n",
        "skip_transcription=False\n",
        "\n",
        "Text = \"\"\n",
        "TextTimestamps = \"\"\n",
        "\n",
        "def seconds_to_time_format(seconds):\n",
        "    hours, remainder = divmod(seconds, 3600)\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}\"\n",
        "\n",
        "\n",
        "def download_youtube_audio_only(url):\n",
        "    yt = YouTube(url)\n",
        "    audio_stream = yt.streams.get_audio_only()\n",
        "    saved_path = audio_stream.download(output_path=\".\", skip_existing=True)\n",
        "    return saved_path\n",
        "\n",
        "\n",
        "def download_youtube_captions(url):\n",
        "    regex = r'(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})'\n",
        "    video_id =  re.search(regex, url).group(1)\n",
        "    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "\n",
        "    try:\n",
        "      transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\n",
        "    except:\n",
        "      for available_transcript in transcript_list:\n",
        "        if available_transcript.is_translatable:\n",
        "          transcript = available_transcript.translate('en').fetch()\n",
        "          break\n",
        "\n",
        "    text = \"\"\n",
        "    for entry in transcript:\n",
        "            start_time = seconds_to_time_format(entry['start'])\n",
        "            text += f\"{start_time} {entry['text'].strip()}\\n\"\n",
        "\n",
        "    transcript_file_name = f\"{video_id}_captions.md\"\n",
        "\n",
        "    with open(transcript_file_name, 'w', encoding='utf-8') as f:\n",
        "      f.write(Text)\n",
        "\n",
        "    return text,transcript_file_name\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "    if use_Youtube_captions:\n",
        "      Text, transcript_file_name = download_youtube_captions(URL)\n",
        "      skip_transcription=True\n",
        "    else:\n",
        "      video_path_local_list.append(download_youtube_audio_only(URL))\n",
        "\n",
        "elif Type == \"Google Drive video link\":\n",
        "  subprocess.run(['ffmpeg', '-y', '-i', '/gdrive/My Drive/' + URL, '-vn', '-acodec', 'pcm_s16le',\n",
        "                  '-ar', '16000', '-ac', '1', 'gdrive_audio.wav'], check=True)\n",
        "  video_path_local_list.append(\"gdrive_audio.wav\")\n",
        "\n",
        "elif Type == \"Dropbox video link\":\n",
        "    subprocess.run(['wget', '-O', 'dropbox_video.mp4', UnprocessableEntityError], check=True)\n",
        "    subprocess.run(['ffmpeg', '-y', '-i', 'dropbox_video.mp4', '-vn', '-acodec', 'pcm_s16le',\n",
        "                    '-ar', '16000', '-ac', '1', 'dropbox_video_audio.wav'], check=True)\n",
        "    video_path_local_list.append(\"dropbox_video_audio.wav\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iOTFm1vPAVDh",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# @markdown ## Transcription using Faster Whisper\n",
        "# @markdown Manually specifying the language can increase speed.\n",
        "\n",
        "if not skip_transcription:\n",
        "\n",
        "  language = \"en\" # @param {type:\"string\"}\n",
        "  # @markdown An initial prompt with specific context-aware words and names can improve accuracy.\n",
        "\n",
        "  initial_prompt = \"\" # @param {type:\"string\"}\n",
        "\n",
        "  video_path_local = str(video_path_local_list[0])\n",
        "\n",
        "\n",
        "  model = WhisperModel('small', device=\"cuda\", compute_type='int8')\n",
        "  segments, info = model.transcribe(str(video_path_local), beam_size=5,\n",
        "                                    language=None if language == \"auto\" else language,\n",
        "                                    task=\"translate\",\n",
        "                                    initial_prompt=initial_prompt)\n",
        "\n",
        "  transcript_file_name = video_path_local.replace(\".mp4\", \".md\")\n",
        "\n",
        "  with open(transcript_file_name, 'w') as f:\n",
        "    for segment in segments:\n",
        "      start_time = seconds_to_time_format(segment.start)\n",
        "      Text += f\"[{start_time}] {segment.text.strip()} \"\n",
        "\n",
        "    f.write(Text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fWeEGfgFAoni",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @markdown ## Summarization and elaboration\n",
        "\n",
        "prompt_type = \"Summarization\"  # @param ['Summarization', 'Only grammar correction with highlights']\n",
        "\n",
        "# Define your prompts using a dictionary for easier management\n",
        "prompts = {\n",
        "    'Summarization': \"\"\"Summarize the video transcript excerpt including a concise title that reflects the content. Wrap the title with **markdown bold notation**. Write the summary as if you are continuing a conversation without needing to signal a beginning. Here is the transcript: \"\"\",\n",
        "    'Only grammar correction with highlights': \"\"\"Repeat the following text correcting any grammatical errors and formatting error. Highlight only the important quote (if there are any) with **markdown bold notation**. Focus solely on the essence of the content as if you are continuing a conversation without using any form of introduction like 'Here's the corrected text:'. Here is the text to fix: \"\"\"\n",
        "}\n",
        "\n",
        "# Select the appropriate prompt\n",
        "summary_prompt = prompts[prompt_type]\n",
        "\n",
        "def summarize(prompt):\n",
        "    if OpenAI_endpoint:\n",
        "      model=\"gpt-3.5-turbo\"\n",
        "    else:\n",
        "      model=\"mixtral-8x7b-32768\"\n",
        "    completion = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "            {\"role\": \"system\", \"content\": summary_prompt},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=4096\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "def extract_timestamp_ranges(timestamp_chunks):\n",
        "    timestamp_pattern = re.compile(r'(\\d{2}:\\d{2}:\\d{2})')\n",
        "    return [f\"{matches[0]}\" for chunk in timestamp_chunks if (matches := timestamp_pattern.findall(chunk))]\n",
        "\n",
        "def format_timestamp_link(timestamp):\n",
        "    \"\"\"Formats a markdown link to a YouTube video with a specific start time.\"\"\"\n",
        "    hours, minutes, seconds = map(int, timestamp.split(':'))\n",
        "    total_seconds = hours * 3600 + minutes * 60 + seconds\n",
        "    return f\"{timestamp} - {URL}&t={total_seconds}\"\n",
        "\n",
        "def process_and_summarize(text):\n",
        "    chunk_size, overlap_size = 4096, 40\n",
        "    texts = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size - overlap_size)]\n",
        "    timestamp_ranges = extract_timestamp_ranges(texts)\n",
        "    summary = []\n",
        "\n",
        "    for idx, text_chunk in enumerate(texts):\n",
        "        summarized_chunk = summarize(text_chunk)\n",
        "        summary_piece = format_timestamp_link(timestamp_ranges[idx]) + \" \" + summarized_chunk\n",
        "        summary_piece += \"\\n\"\n",
        "        summary.append(summary_piece)\n",
        "\n",
        "    # Save the final summary\n",
        "    final_name =  transcript_file_name.replace(\".md\", \"_FINAL.md\") if Type != \"Dropbox video link\" else \"final_dropbox_video.md\"\n",
        "    with open(final_name, 'w') as f:\n",
        "        f.write(\"\\n\\n\".join(summary))\n",
        "\n",
        "process_and_summarize(Text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}