{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkogwIy7IfQO"
      },
      "source": [
        "# Transcription and summarization notebook with AIs\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Repository: https://github.com/martinopiaggi/summarize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "jwROe6WH2lZi"
      },
      "outputs": [],
      "source": [
        "Source = \"https://www.youtube.com/watch?v=kpTJqwIfHcM\" #@param {type:\"string\"}\n",
        "Type_of_source = \"Youtube video or playlist\" #@param ['Youtube video or playlist', 'Videos on Google Drive folder','Dropbox video link']\n",
        "\n",
        "Type = Type_of_source\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Insert necessary API keys depending on which model you want to use\n",
        "openai_api_key = \"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\" #@param {type:\"string\"}\n",
        "\n",
        "mistral_api_key = \"nmAtroUadtpCFNZjdbp530e9NccoVp9b\" #@param {type:\"string\"}\n",
        "\n",
        "groq_api_key = \"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\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown Do you want to use Mistral Tiny as summarization model?\n",
        "MistralTiny = True  #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "URL = Source\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Advanced settings\n",
        "\n",
        "#@markdown You want timestamps in final summary?\n",
        "Timestamps = True #@param {type:\"boolean\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sJnZWCPc3uOH",
        "outputId": "b92aa54a-ed98-4faa-b4d0-b2993a73d90b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Collecting groq\n",
            "  Downloading groq-0.4.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.16.3)\n",
            "Installing collected packages: groq\n",
            "Successfully installed groq-0.4.2\n",
            "Requirement already satisfied: faster-whisper in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: av==11.* in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (11.0.0)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (4.1.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.20.3)\n",
            "Requirement already satisfied: tokenizers<0.16,>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.15.2)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (1.17.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (1.25.2)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (24.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (24.3.7)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.12)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Collecting git+https://github.com/pytube/pytube\n",
            "  Cloning https://github.com/pytube/pytube to /tmp/pip-req-build-dxeknxrh\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pytube/pytube /tmp/pip-req-build-dxeknxrh\n",
            "  Resolved https://github.com/pytube/pytube to commit a32fff39058a6f7e5e59ecd06a7467b71197ce35\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#@markdown ## Installation of libraries\n",
        "#@markdown Installation of libraries\n",
        "\n",
        "!pip install transformers\n",
        "!pip install tensorflow\n",
        "from transformers import pipeline,BartTokenizer, BartForConditionalGeneration\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "!pip install groq\n",
        "from groq import Groq\n",
        "\n",
        "\n",
        "#if MistralTiny:\n",
        "  #!pip install mistralai\n",
        "  #from mistralai.client import MistralClient\n",
        " # from mistralai.models.chat_completion import ChatMessage\n",
        " # client = MistralClient(mistral_api_key)\n",
        "#else:\n",
        "#  !pip install openai\n",
        " # import openai\n",
        " # client = openai.OpenAI(\n",
        " #     api_key=openai_api_key,\n",
        "#  )\n",
        "\n",
        "\n",
        "import re\n",
        "import math\n",
        "\n",
        "\n",
        "!pip install faster-whisper\n",
        "from faster_whisper import WhisperModel\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "  !pip install git+https://github.com/pytube/pytube\n",
        "  from pytube import YouTube\n",
        "\n",
        "if Type == (\"Dropbox video link\"):\n",
        "  !sudo apt update && sudo apt install ffmpeg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "eLIU6bAX9a9v"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Video downloads\n",
        "#@markdown Downloading video sources\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "  video_path_local_list = []\n",
        "\n",
        "# Function to download and extract audio from YouTube videos or playlists\n",
        "def download_youtube_audio(url):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'outtmpl': f'./%(id)s.%(ext)s',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "            'preferredquality': '128',\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        info_dict = ydl.extract_info(url, download=True)\n",
        "        filename = ydl.prepare_filename(info_dict)\n",
        "        return Path(filename).with_suffix('.wav')\n",
        "\n",
        "\n",
        "from pytube import YouTube\n",
        "import os\n",
        "\n",
        "def download_youtube_audio_only(url, output_dir=\".\", filename=None, filename_prefix=None, skip_existing=True, timeout=None, max_retries=0):\n",
        "    yt = YouTube(url)\n",
        "    audio_stream = yt.streams.get_audio_only()  # No subtype specified; it will choose the best available.\n",
        "\n",
        "    # Prepare the filename if a prefix is provided.\n",
        "    if filename_prefix and filename:\n",
        "        filename = f\"{filename_prefix}{filename}\"\n",
        "    elif filename_prefix:\n",
        "        filename = f\"{filename_prefix}{audio_stream.default_filename}\"\n",
        "\n",
        "    # Download the audio stream.\n",
        "    saved_path = audio_stream.download(output_path=output_dir, filename=filename, skip_existing=skip_existing, timeout=timeout, max_retries=max_retries)\n",
        "\n",
        "    return saved_path  # Returns the path to the saved audio file.\n",
        "\n",
        "\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "    audio_path = download_youtube_audio_only(URL)  # Capture the returned path\n",
        "    video_path_local_list.append(audio_path)\n",
        "\n",
        "\n",
        "\n",
        "# Function to download and convert Dropbox video to audio\n",
        "def download_dropbox_video(dropbox_url, output_audio_path='dropbox_video_audio.wav'):\n",
        "    subprocess.run(['wget', '-O', 'dropbox_video.mp4', dropbox_url], check=True)\n",
        "    subprocess.run(['ffmpeg', '-i', 'dropbox_video.mp4', '-vn', '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1', output_audio_path], check=True)\n",
        "\n",
        "\n",
        "video_path_local_list = []\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "    #audio_path = download_youtube_audio(URL)\n",
        "    download_youtube_audio_only(URL)\n",
        "    video_path_local_list.append(audio_path)\n",
        "\n",
        "\n",
        "elif Type == \"Dropbox video link\":\n",
        "    download_dropbox_video(URL)\n",
        "    video_path_local_list.append(\"dropbox_video_audio.wav\")\n",
        "    print(\"Downloaded and converted Dropbox video to audio.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "iOTFm1vPAVDh"
      },
      "outputs": [],
      "source": [
        "# @markdown ## Transcription\n",
        "\n",
        "# @markdown Manually specifying the language can increase speed.\n",
        "\n",
        "language = \"en\" #@param {type:\"string\"}\n",
        "# @markdown An initial prompt with specific context-aware words and names can improve accuracy.\n",
        "\n",
        "initial_prompt = \"\" #@param {type:\"string\"}\n",
        "Text = \"\"\n",
        "TextTimestamps = \"\"\n",
        "\n",
        "video_path_local = str(video_path_local_list[0])\n",
        "\n",
        "def seconds_to_time_format(s):\n",
        "    hours = s // 3600\n",
        "    s %= 3600\n",
        "    minutes = s // 60\n",
        "    s %= 60\n",
        "    seconds = s // 1\n",
        "    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}\"\n",
        "\n",
        "\n",
        "model = WhisperModel('small', device=\"cuda\", compute_type='int8')\n",
        "segments, info = model.transcribe(str(video_path_local), beam_size=5,\n",
        "                                  language=None if language == \"auto\" else language,\n",
        "                                  task=\"translate\",\n",
        "                                  initial_prompt=initial_prompt)\n",
        "\n",
        "transcript_file_name = video_path_local.replace(\".mp4\", \".txt\")\n",
        "transcript_file_name_timestamps = video_path_local.replace(\".wav\", \"\") + \"Timestamps\" + \".txt\"\n",
        "\n",
        "with open(transcript_file_name, 'w') as f:\n",
        "  for segment in segments:\n",
        "    start_time = seconds_to_time_format(segment.start)\n",
        "    Text += segment.text.strip() + \" \"\n",
        "    TextTimestamps += f\"[{start_time}] {segment.text.strip()} \"\n",
        "\n",
        "  f.write(Text)\n",
        "  with open(transcript_file_name_timestamps, 'w') as ft:\n",
        "    ft.write(TextTimestamps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "fWeEGfgFAoni"
      },
      "outputs": [],
      "source": [
        "# @markdown ## Summarization and elaboration\n",
        "\n",
        "# @markdown Manually specifying the language can increase speed.\n",
        "\n",
        "summary_prompt = \"\"\"Rewrite this video transcript excerpt into a concise summary. Correct any transcription errors. Start the summary with direct statements about the content, completely omitting any form of introduction or mention of 'summary', 'the speaker', 'this video', or 'this transcript'. Focus solely on the essence of the content as if you are continuing a conversation without needing to signal a beginning:  \"\"\"\n",
        "\n",
        "#summary_prompt = \"\"\"Repeat the following text correcting any grammatical errors. Focus solely on the essence of the content as if you are continuing a conversation without using any form of introduction like 'Here's the corrected text:' . Here is the text to fix: \"\"\"\n",
        "\n",
        "def query_openai_gpt(prompt, model=\"gpt-3.5-turbo\", max_tokens=4096):\n",
        "    try:\n",
        "        completion = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\":  prompt}\n",
        "            ],\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "        # Assuming the response structure has a 'choices' field with a list of completions,\n",
        "        # and each completion contains a 'message' field with the actual text.\n",
        "        return completion.choices[0].message.content\n",
        "    except Exception as e:  # General exception handling\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "\n",
        "def query_mistral_gpt(prompt, model=\"mistral-tiny\", max_tokens=4096):\n",
        "    try:\n",
        "        messages = [ChatMessage(role=\"user\", content=prompt)]\n",
        "\n",
        "        # Call the chat method to get a response for the prompt\n",
        "        chat_response = client.chat(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "\n",
        "        # Retrieve and return the content of the response\n",
        "        return chat_response.choices[0].message.content\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "\n",
        "def query_groq_api(prompt, model=\"mixtral-8x7b-32768\", max_tokens=4096):\n",
        "    client = Groq(api_key=groq_api_key)  # Initialize the Groq client\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": summary_prompt},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        model=model,\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "\n",
        "    return chat_completion.choices[0].message.content\n",
        "\n",
        "\n",
        "def summarize(prompt):\n",
        "    return query_groq_api(prompt)\n",
        "    #if MistralTiny:\n",
        "   #   return query_mistral_gpt(summary_prompt + prompt)\n",
        "   ## else:\n",
        "  #    return query_openai_gpt(summary_prompt + prompt)\n",
        "\n",
        "\n",
        "\n",
        "# Define the TextDataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.texts = texts\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.texts[idx]\n",
        "\n",
        "# Function to extract timestamp ranges\n",
        "def extract_timestamp_ranges(text_timestamp_chunks):\n",
        "    timestamp_pattern = re.compile(r'\\[(\\d{2}:\\d{2}:\\d{2})\\]')\n",
        "    ranges = []\n",
        "\n",
        "    for chunk in text_timestamp_chunks:\n",
        "        matches = timestamp_pattern.findall(chunk)\n",
        "        if matches:\n",
        "            start_time = matches[0]\n",
        "            ranges.append(f\"[{start_time}]\")\n",
        "    return ranges\n",
        "\n",
        "# Process and summarize text\n",
        "def process_and_summarize(Text, TextTimestamps=None):\n",
        "    chunk_size = 4096\n",
        "    overlap_size = 100\n",
        "\n",
        "    texts = [Text[i:i+chunk_size] for i in range(0, len(Text), chunk_size - overlap_size)]\n",
        "    dataset = TextDataset(texts)\n",
        "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    summary = ''\n",
        "    summaryTimestamps = ''\n",
        "\n",
        "    if TextTimestamps:\n",
        "        ratio = len(TextTimestamps) / len(Text)\n",
        "        timestamps_chunk_size = int(chunk_size * ratio)\n",
        "        timestamps_overlap_size = int(overlap_size * ratio)\n",
        "        text_timestamps_chunks = [TextTimestamps[i:i+timestamps_chunk_size] for i in range(0, len(TextTimestamps), timestamps_chunk_size - timestamps_overlap_size)]\n",
        "        timestamp_ranges = extract_timestamp_ranges(text_timestamps_chunks)\n",
        "\n",
        "    ts_idx = 0\n",
        "\n",
        "    for idx, batch in enumerate(dataloader):\n",
        "        text_chunk = batch[0]\n",
        "        summarized_chunk = summarize(text_chunk)\n",
        "        summary += summarized_chunk + \"\\n\"\n",
        "\n",
        "        if TextTimestamps and idx < len(timestamp_ranges):\n",
        "            summaryTimestamps += timestamp_ranges[idx] + \" \" + summarized_chunk + \"\\n\\n\"\n",
        "        else:\n",
        "            summaryTimestamps += summarized_chunk + \"\\n\"\n",
        "\n",
        "    # Save the final summar\n",
        "    final_name =  transcript_file_name.replace(\".txt\", \"_SUMMARY.txt\") if Type != \"Dropbox video link\" else \"summary_dropbox_video_audio.txt\"\n",
        "    with open(final_name, 'w') as f:\n",
        "        f.write(summaryTimestamps)\n",
        "\n",
        "process_and_summarize(Text, TextTimestamps)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}